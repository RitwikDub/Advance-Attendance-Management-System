{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30ca553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60199564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1168 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_path = r\"G:\\Downloads\\attendease_Image_Data_Raw\\test_face\"\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d03e3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(r\"G:\\Downloads\\attendease_Image_Data_Raw\\attendnce_model.h5\")\n",
    "#loaded_model = load_model(r\"G:\\Downloads\\attendease_Image_Data_Raw\\atndnc_face_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ce3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 156s 4s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dada457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mappings for classes present in the training and validation datasets\n",
      "\n",
      "0 : 02_Abishek_Banerjee\n",
      "1 : 06_Ayan_Datta\n",
      "2 : 07_Ayush_Mitra\n",
      "3 : 13_Chhavi_Baliyan\n",
      "4 : 16_Priyal_Dighe\n",
      "5 : 17_Dilpreet_Kaur\n",
      "6 : 19_Ekta_Chaware\n",
      "7 : 22_Aman_Jawalekar\n",
      "8 : 28_Kinjal_Bandopadhyay\n",
      "9 : 38_Ritwik_Dubey\n",
      "10 : 40_Sahil_Raj\n",
      "11 : 44_Gaurav_Sharma\n",
      "12 : 46_shivani_shukla\n",
      "13 : 58_Rutvik_Sawant\n"
     ]
    }
   ],
   "source": [
    "labels = {value: key for key, value in test_generator.class_indices.items()}\n",
    "\n",
    "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
    "for key, value in labels.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86abdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained Haar Cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(r\"G:\\Downloads\\opencv data\\Computer-Vision-with-Python\\DATA\\haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread(r\"G:\\Downloads\\attendease_Image_Data_Raw\\Image_Data_Raw\\28_Kinjal_Bandopadhyay\\28_Kinjal_Bandopadhyay_812.jpg\")\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(image, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "# Crop and display each face\n",
    "for i, (x, y, w, h) in enumerate(faces):\n",
    "    # Crop the face region\n",
    "    cropped_face = image[y:y+h, x:x+w]\n",
    "    cropped_face_rgb = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)  # Convert to RGB for Matplotlib\n",
    "\n",
    "    # Plot the cropped face\n",
    "    plt.imshow(cropped_face_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Face {i+1}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9ddec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained LBP Cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(r'G:\\Downloads\\opencv data\\Computer-Vision-with-Python\\DATA\\lbpcascades\\lbpcascade_frontalface_improved.xml')\n",
    "# Load an image\n",
    "image = cv2.imread(r\"G:\\Downloads\\attendease_Image_Data_Raw\\Image_Data_Raw\\28_Kinjal_Bandopadhyay\\28_Kinjal_Bandopadhyay_812.jpg\")\n",
    "\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Crop and display each face\n",
    "for i, (x, y, w, h) in enumerate(faces):\n",
    "    # Crop the face region\n",
    "    cropped_face = image[y:y+h, x:x+w]\n",
    "    cropped_face_rgb = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)  # Convert to RGB for Matplotlib\n",
    "    x_input=cv2.resize(cropped_face_rgb,(224,224))\n",
    "    x_input=np.array(x_input).reshape(1,224,224,3)\n",
    "\n",
    "    # Plot the cropped face\n",
    "    #plt.imshow(cropped_face_rgb)\n",
    "    #plt.axis('off')\n",
    "    #plt.title(f'Face {i+1}')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a7bdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d575ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=x_input/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4b402b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 379ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=loaded_model.predict(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f14701db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1078452e-02, 6.5828704e-11, 5.5630926e-07, 2.5943345e-11,\n",
       "        9.6772511e-19, 6.3324959e-26, 3.7688365e-14, 2.5594329e-15,\n",
       "        9.7892100e-01, 1.7112613e-14, 7.1956091e-12, 1.3556200e-19,\n",
       "        0.0000000e+00, 2.9545731e-18]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "822bb705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: 28_Kinjal_Bandopadhyay\n"
     ]
    }
   ],
   "source": [
    "predicted_class = np.argmax(prediction)\n",
    "print(\"Student:\", labels[predicted_class])\n",
    "student=labels[predicted_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57628b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c31248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4423d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 1s 562ms/step\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(r'G:\\Downloads\\opencv data\\Computer-Vision-with-Python\\DATA\\lbpcascades\\lbpcascade_frontalface_improved.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    #rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Crop and display each face\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "    # Crop the face region\n",
    "        cropped_face = frame[y:y+h, x:x+w]\n",
    "        cropped_face_rgb = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)  # Convert to RGB for Matplotlib\n",
    "        x_input=cv2.resize(cropped_face_rgb,(224,224))\n",
    "        x_input=np.array(x_input).reshape(1,224,224,3)\n",
    "        x_input=x_input/255.0\n",
    "    \n",
    "    \n",
    "        prediction=loaded_model.predict(x_input)\n",
    "    \n",
    "    \n",
    "        predicted_class = np.argmax(prediction)\n",
    "        #print(\"Student:\", labels[predicted_class])\n",
    "    \n",
    "        font=cv2.FONT_HERSHEY_COMPLEX\n",
    "        identity=labels[predicted_class]\n",
    "        cv2.putText(frame,identity,(100,100),font,1,(0,255,0),2,cv2.LINE_4)\n",
    "    \n",
    "    cv2.imshow('Attendance Management System',frame)\n",
    "    if cv2.waitKey(2) & 0xff==ord('q'):\n",
    "        \n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd6b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
